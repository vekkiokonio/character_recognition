{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character classifier with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a classifier to recognize English characters. We used the dataset called EnglishImg from http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/. This dataset contains digits and English carachters (lower and uppercase). We choose *Keras* to implement our classifier: when the depth of a neural network increases, it becomes difficult to take care of all parameters; differently from, e.g., TensorFlow or Theano, Keras provides an intuitive way to tune complex neural networks. We think it is the most appropriate library to build fast and efficient classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the libraries used in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Variable initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize the variables we are going to use in the notebook. After running the shell script format_dataset.sh, the dataset is moved to /img and split into three folders (/train, /valid and /test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 224\n",
    "height = 224\n",
    "nb_epoch = 5\n",
    "training_path = 'img/train'\n",
    "validation_path = \"img/valid\"\n",
    "test_path = \"img/test\"\n",
    "training_batch = 10\n",
    "validation_batch = 4\n",
    "test_batch = 10\n",
    "nb_class = len(next(os.walk(training_path))[1])\n",
    "class_label = list(string.digits + string.ascii_uppercase + string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the dataset loader by using the *ImageDataGenerator* function of Keras. Preprocessing the images is important to train appropriately the network, and the parameters can be tuned (e.g., target size) to improve the classifier accuracy. What is more, the usage of the image mask can further improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                             rotation_range = 20,\n",
    "                             width_shift_range = 0.2,\n",
    "                             height_shift_range = 0.2,\n",
    "                             horizontal_flip = True,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "training = datagen.flow_from_directory(training_path,\n",
    "                                       target_size = (width, height),\n",
    "                                       batch_size = training_batch,\n",
    "                                       class_mode = 'categorical')\n",
    "validation = datagen.flow_from_directory(validation_path,\n",
    "                                         target_size = (width, height),\n",
    "                                         batch_size = validation_batch,\n",
    "                                         class_mode = 'categorical')\n",
    "\n",
    "nb_classes = len(next(os.walk(training_path))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Load the VGG model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our classifier we used the pre-trained network called *VGG16* which has been trained with images. As an alternative, we could use, e.g., *resnet*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_conv = VGG16(weights = 'imagenet', include_top = False, input_shape = (width, height, 3))\n",
    "\n",
    "# Freeze the layers except the last 4 layers\n",
    "for layer in vgg_conv.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fine tune the VGG model by adding four layers to reduce overfitting (*layers.Dropout()*), and output probabilities for classes (*layers.Dense()* with *softmax* activation function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model and add the VGG convolutional base model\n",
    "model = models.Sequential()\n",
    "model.add(vgg_conv)\n",
    " \n",
    "# Add new layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(nb_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile the model with the optimizer *RMSprop*. We tested *Adam* with default parameters, but it provided worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optimizers.RMSprop(lr = 1e-4),\n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model over five epochs and we validate to analyze overfitting. We store the resulting weights in a file. Alternatively, it is possible to restore previous computed weights through the command *model.load_weights('model/vgg16.h5')*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(training,\n",
    "                              steps_per_epoch = len(training),\n",
    "                              epochs = nb_epoch,\n",
    "                              validation_data = validation,\n",
    "                              validation_steps = len(validation),\n",
    "                              verbose = 2)\n",
    "\n",
    "model.save_weights('model/vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Plot the training graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the accuracy and the loss per epoch for the training and the validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize = (10, 8))\n",
    "   \n",
    "# Plot accuracy\n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.legend(['train', 'validation'], loc='upper right')  \n",
    "\n",
    "# Plot loss  \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'validation'], loc='upper right')  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 - Make predictions on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the model generated, we compute the probability that an image belongs to a certain class (*prediction_prob*). Conversely, the variable *prediction* describes which class has the highest probability per image. We also extract images (in *test_image*) and labels (in *test_label*) from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datagen.flow_from_directory(test_path,\n",
    "                                   target_size = (width, height),\n",
    "                                   batch_size = test_batch,\n",
    "                                   shuffle = False,\n",
    "                                   class_mode = 'categorical')\n",
    "\n",
    "prediction_prob = model.predict_generator(test, steps = len(test))\n",
    "\n",
    "# Choose the class with the highest probability\n",
    "best_prediction = np.argmax(prediction_prob, axis = 1)\n",
    "prediction = np.zeros((len(prediction_prob), nb_classes))\n",
    "\n",
    "for i in range(len(best_prediction)):\n",
    "    prediction[i, best_prediction[i]] = 1   \n",
    "\n",
    "# Extract images and labels from the test set\n",
    "test_image = []\n",
    "test_label = np.zeros((len(prediction), nb_class))\n",
    "test.reset()\n",
    "\n",
    "i = 0\n",
    "while i < len(test):\n",
    "    x, y = test.next()\n",
    "\n",
    "    for j in range(len(x)):\n",
    "        type(x[j])\n",
    "        test_images.append(x[j])\n",
    "    \n",
    "        for w in range(nb_class):\n",
    "            test_label[i * 10 + j, w] = y[j][w]\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 - Print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the accuracy of the model as the percentage of correct predictions divided by the total number of predictions. The prediction used is the processed 0/1 variable *prediction* described in Step 8. A possible improvement of this metric should also take into account the probabilities of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = np.max(prediction - test_label, axis=1)\n",
    "accuracy = np.around((1 - int(np.sum(error)) / len(prediction)) * 100, 2)\n",
    "print('Accuracy:', accuracy, '% -', int(np.sum(error)), 'errors out of', len(prediction), 'images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 - Show errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell gives the opportunity to visually inspect on which images the classifier is making errors. This is important to analyze the result of the classifier, and improve the model accordingly.<br>\n",
    "**RECOMMENDED USE:** limit the number of images to show when the number of errors is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_index = np.where(error == 1)[0]\n",
    "print(error_index)\n",
    "for i in range(len(error_index)):\n",
    "    a = np.argmax(prediction_prob[error_index[i], :])\n",
    "    b = np.max(prediction_prob[error_index[i], :])\n",
    "    print('Predict', a, 'with probability ', np.around(b * 100, 2), '%')\n",
    "    plt.imshow(test_images[error_index[i]])            # print the name of the class\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus step - Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show here an alternative model built from scratch. This could be used instead of Steps 3 and 4. However, it provides bad accuracy if not trained with a large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), input_shape = (width, height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (width, height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (width, height, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(nb_classes, activation = 'softmax'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
